{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2fdf97-bbc6-4973-bdde-db769f3b2585",
   "metadata": {},
   "source": [
    "# Pipeline of Digits\n",
    "\n",
    "This is a starting notebook for solving the \"Pipeline of Digits\" assignment.\n",
    "\n",
    "\n",
    "This notebook was created by [Santiago L. Valdarrama](https://twitter.com/svpino) as part of the [Machine Learning School](https://www.ml.school) program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae06bac-01d0-477e-b9f8-1fdd3ebf3dc7",
   "metadata": {},
   "source": [
    "Let's make sure we are running the latest version of the SakeMaker's SDK. **Restart the notebook** after you upgrade the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61dd97d-7df3-418d-a1de-93f8fcfaeceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade pip\n",
    "# !pip install -q --upgrade awscli boto3\n",
    "# !pip install -q --upgrade sagemaker==2.146.0\n",
    "# !pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8736d294-1434-4739-82a3-d0e7414a41bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61a1e76-dd73-4e56-b476-e9a9afde9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import argparse\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa815b2-b779-4af0-929c-a409af36a85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iam_client = boto3.client(\"iam\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98619548-6458-4ebd-afcb-547bd2488dae",
   "metadata": {},
   "source": [
    "## Creating the S3 Bucket\n",
    "\n",
    "Let's create an S3 bucket where you will upload all the information generated by the pipeline. Make sure you set `BUCKET` to the name of the bucket you want to use. This name has to be unique.\n",
    "\n",
    "If you want to create a bucket in a region other than `us-east-1`, use this command instead:\n",
    "\n",
    "```\n",
    "!aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$region\n",
    "```\n",
    "\n",
    "The `LocationConstraint` argument should specify the region where you want to create the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ee4d0e-d3a6-4ac3-bd60-e04dd7028ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "BUCKET = \"mlschool01\"\n",
    "\n",
    "!aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580ab4f-7a15-495d-9fbd-cacb546c9536",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We have two CSV files containing the MNIST dataset. These files come from the [MNIST in CSV](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv) Kaggle dataset.\n",
    "\n",
    "The `mnist_train.csv` file contains 60,000 training examples and labels. The `mnist_test.csv` contains 10,000 test examples and labels. Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf401e-0e1f-4ef8-824a-98e975438054",
   "metadata": {},
   "source": [
    "Let's extract the `dataset.tar.gz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba4210d6-f612-4f7b-9b18-397e2a8ac8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/\n",
      "dataset/mnist_test.csv\n",
      "dataset/mnist_train.csv\n"
     ]
    }
   ],
   "source": [
    "MNIST_FOLDER = Path('/root/ml.school/mnist')\n",
    "# MNIST_FOLDER = \"/root/ml.school/mnist\"\n",
    "DATASET_FOLDER = Path(MNIST_FOLDER) / \"dataset\"\n",
    "\n",
    "!tar -xvzf $MNIST_FOLDER/dataset.tar.gz -C $MNIST_FOLDER --no-same-owner\n",
    "\n",
    "# TRIM ORIGINAL MNIST DATASET SO THAT IT CAN BE USED WITH THE FREE KERNEL FROM SAGEMAKER\n",
    "# df = pd.read_csv(DATASET_FOLDER / \"mnist_train.csv\")\n",
    "# train, _ = np.split(df, [int(.7 * len(df))])\n",
    "# pd.DataFrame(train).to_csv(Path(MNIST_FOLDER) / \"dataset/mnist_train.csv\", index=False)\n",
    "# # df.shape\n",
    "# train\n",
    "# !tar -xvzf $MNIST_FOLDER/dataset.tar.gz -C $MNIST_FOLDER --no-same-owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6bf283-358f-4cf4-8355-e0ac5f67896d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FOLDER / \"mnist_train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df65826-f4e1-4683-8bfe-b7889bf8eec9",
   "metadata": {},
   "source": [
    "Let's load the first 10 rows of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019d1b-4bac-49c5-98bc-ba64174ab084",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Uploading dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0d2b41-3239-4004-b20b-25bdd59b6eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mlschool01//root/ml.school/mnist\n",
      "Train set S3 location: s3://mlschool01/root/ml.school/mnist/mnist_train.csv\n",
      "Test set S3 location: s3://mlschool01/root/ml.school/mnist/mnist_test.csv\n"
     ]
    }
   ],
   "source": [
    "S3_FILEPATH = f\"s3://{BUCKET}/{MNIST_FOLDER}\"\n",
    "\n",
    "\n",
    "TRAIN_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / \"mnist_train.csv\"),\n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "TEST_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / \"mnist_test.csv\"), \n",
    "    desired_s3_uri=S3_FILEPATH,\n",
    ")\n",
    "\n",
    "print (S3_FILEPATH)\n",
    "print(f\"Train set S3 location: {TRAIN_SET_S3_URI}\")\n",
    "print(f\"Test set S3 location: {TEST_SET_S3_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fceda727-32fd-4c37-84e5-722007022db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8999, 785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = pd.read_csv(\"s3://mlschool01//root/ml.school/mnist/preprocessing/test.csv\")\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2578a-b71f-4e6a-a4d4-7caee35dd234",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ced0821f-63a5-4e6f-a0b1-6b921e8d61e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /root/ml.school/mnist/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MNIST_FOLDER}/preprocessor.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from pickle import dump\n",
    "\n",
    "# This is the location where the SageMaker Processing job\n",
    "# will save the input dataset.\n",
    "BASE_DIR = \"/opt/ml/processing\"\n",
    "DATA_FILEPATH = Path(BASE_DIR) / \"input\" / \"mnist_train.csv\"\n",
    "\n",
    "# # FOR LOCAL TESTING\n",
    "# BASE_DIR = '/root/ml.school/mnist/opt/ml/processing'\n",
    "# DATA_FILEPATH = Path(DATASET_FOLDER) /  \"mnist_train.csv\"\n",
    "\n",
    "def save_splits(base_dir, train, validation, test):\n",
    "    \"\"\"\n",
    "    One of the goals of this script is to output the three\n",
    "    dataset splits. This function will save each of these\n",
    "    splits to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_path = Path(base_dir) / \"train\" \n",
    "    validation_path = Path(base_dir) / \"validation\" \n",
    "    test_path = Path(base_dir) / \"test\"\n",
    "    \n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(validation_path / \"validation.csv\", header=False, index=False)\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "    \n",
    "def save_pipeline(base_dir, pipeline):\n",
    "    \"\"\"\n",
    "    Saves the Scikit-Learn pipeline that we used to\n",
    "    preprocess the data.\n",
    "    \"\"\"\n",
    "    pipeline_path = Path(base_dir) / \"pipeline\"\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / \"pipeline.pkl\", 'wb'))\n",
    "    \n",
    "def generate_baseline_dataset(split_name, base_dir, X, y):\n",
    "    \"\"\"\n",
    "    To monitor the data and the quality of our model we need to compare the \n",
    "    production quality and results against a baseline. To create those baselines, \n",
    "    we need to use a dataset to compute statistics and constraints. That dataset\n",
    "    should contain information in the same format as expected by the production\n",
    "    endpoint. This function will generate a baseline dataset and save it to \n",
    "    disk so we can later use it.\n",
    "    \n",
    "    \"\"\"\n",
    "    baseline_path = Path(base_dir) / f\"{split_name}-baseline\" \n",
    "    baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = X.copy()\n",
    "    \n",
    "    # The baseline dataset needs a column containing the groundtruth.\n",
    "    df[\"groundtruth\"] = y\n",
    "    df[\"groundtruth\"] = df[\"groundtruth\"].values.astype(str)\n",
    "    \n",
    "    # We will use the baseline dataset to generate baselines\n",
    "    # for monitoring data and model quality. To simplify the process, \n",
    "    # we don't want to include any NaN rows.\n",
    "    df = df.dropna()\n",
    "\n",
    "    df.to_json(baseline_path / f\"{split_name}-baseline.json\", orient='records', lines=True)\n",
    "    \n",
    "def preprocess(base_dir, data_filepath):\n",
    "    \"\"\"\n",
    "    Preprocesses the supplied raw dataset and splits it into a train, validation,\n",
    "    and a test set.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_filepath)\n",
    "    numerical_columns = [column for column in df.columns if df[column].dtype in [\"int64\", \"float64\"]]\n",
    "    numerical_columns.remove('label')\n",
    "    \n",
    "    numerical_preprocessor = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numerical\", numerical_preprocessor, numerical_columns)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X = df\n",
    "    columns = list(X.columns)\n",
    "    \n",
    "    X = X.to_numpy()\n",
    "    np.random.shuffle(X)\n",
    "    X, _ = np.split(X, [int(.5 * len(X))])\n",
    "    train, validation, test = np.split(X, [int(.5 * len(X)), int(.7 * len(X))])\n",
    "    \n",
    "    X_train = pd.DataFrame(train, columns=columns)\n",
    "    X_validation = pd.DataFrame(validation, columns=columns)\n",
    "    X_test = pd.DataFrame(test, columns=columns)\n",
    "    \n",
    "    y_train = X_train.label\n",
    "    y_validation = X_validation.label\n",
    "    y_test = X_test.label\n",
    "    \n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_validation = label_encoder.transform(y_validation)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    \n",
    "    X_train.drop([\"label\"], axis=1, inplace=True)\n",
    "    X_validation.drop([\"label\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"label\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Let's generate a dataset that we can later use to compute\n",
    "    # baseline statistics and constraints about the data that we\n",
    "    # used to train our model.\n",
    "    generate_baseline_dataset(\"train\", base_dir, X_train, y_train)\n",
    "    \n",
    "    # To generate baseline constraints about the quality of the\n",
    "    # model's predictions, we will use the test set.\n",
    "    generate_baseline_dataset(\"test\", base_dir, X_test, y_test)\n",
    "    \n",
    "    # Transform the data using the Scikit-Learn pipeline.\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_validation = preprocessor.transform(X_validation)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    train = np.concatenate((X_train, np.expand_dims(y_train, axis=1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, np.expand_dims(y_validation, axis=1)), axis=1)\n",
    "    test = np.concatenate((X_test, np.expand_dims(y_test, axis=1)), axis=1)\n",
    "    \n",
    "    save_splits(base_dir, train, validation, test)\n",
    "    save_pipeline(base_dir, pipeline=preprocessor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(BASE_DIR, DATA_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2877905c-a804-4fb5-83bc-2f928633016b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 785)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FOLDER / \"mnist_train.csv\", nrows = 10)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10066e01-56a9-4d44-ae4d-515048d69581",
   "metadata": {},
   "source": [
    "### TESTING PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ab13c7b-dce8-4999-b882-ff6927609675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from preprocessor import preprocess\n",
    "\n",
    "\n",
    "# def print_baseline(split_name):\n",
    "#     print()\n",
    "#     print(f\"Baseline {split_name}:\")\n",
    "#     with open(Path(directory) / f\"{split_name}-baseline\" / f\"{split_name}-baseline.json\") as baseline:\n",
    "#         lines = [next(baseline) for _ in range(5)]\n",
    "        \n",
    "#     for l in lines:\n",
    "#         print(l[:-1])\n",
    "    \n",
    "\n",
    "# with tempfile.TemporaryDirectory() as directory:\n",
    "#     print (DATASET_FOLDER / \"mnist_train.csv\")\n",
    "#     preprocess(\n",
    "#         base_dir=directory, \n",
    "#         data_filepath= Path(DATASET_FOLDER) / \"mnist_train.csv\"\n",
    "#         # data_filepath = TRAIN_SET_S3_URI\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Folders: {os.listdir(directory)}\")\n",
    "    \n",
    "#     print_baseline(\"train\")\n",
    "#     print_baseline(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa9f4a7c-e0a5-4aef-bfec-14e936118973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=TRAIN_SET_S3_URI,\n",
    ")\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing\",\n",
    ")\n",
    "\n",
    "train_dataset_baseline_destination = ParameterString(\n",
    "    name=\"train_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/train\",\n",
    ")\n",
    "\n",
    "test_dataset_baseline_destination = ParameterString(\n",
    "    name=\"test_dataset_baseline_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/preprocessing/baselines/test\",\n",
    ")\n",
    "\n",
    "timestamp_signature = ParameterString(\n",
    "    name=\"timestamp_signature\",\n",
    "    default_value=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91496cc-e166-4a96-868a-19a0e9da5714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec2c2b83-5016-4597-8755-0753e0f875cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"mnist-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type='ml.t3.medium',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d798797c-6573-49c4-92d7-282d1c5f0f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_step = ProcessingStep(\n",
    "    name=\"preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\", destination=train_dataset_baseline_destination),\n",
    "        ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\", destination=test_dataset_baseline_destination),\n",
    "    ],\n",
    "    code=f\"{MNIST_FOLDER}/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af60dd7e-1ea8-4e73-b5dc-bd3ac954afe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session1_pipeline1 = Pipeline(\n",
    "    name=\"mnist-session1-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93602c18-2764-4e66-aeeb-46e5a8a9451b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RUN PIPELINE FOR SESSION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3d816c-3036-456f-811d-db587d9e1273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session1_pipeline1.upsert(role_arn=role)\n",
    "# execution = session1_pipeline1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49948e6-ca47-4ae6-ae16-de4112e14c81",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e36e1b0-8f34-48f7-a105-7538b3bffbba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.parameter import IntegerParameter, ContinuousParameter\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f7d09a-ab50-4660-80f7-f5ee8a27b8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /root/ml.school/mnist/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MNIST_FOLDER}/train.py\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import boto3\n",
    "\n",
    "# import torchmetrics\n",
    "# from torchmetrics.classification import MulticlassAccuracy\n",
    "import time\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        # self.accuracy = MulticlassAccuracy(num_classes=10)\n",
    "        self.val_acc = 0\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.flatten(input_data)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    \n",
    "    def validation_accuracy(self, inputs, vals):\n",
    "        pred = self(inputs).detach().numpy()\n",
    "        predictions = np.argmax(pred, axis=-1)\n",
    "        self.val_acc = accuracy_score(vals, predictions)\n",
    "        # self.log('val_acc', self.accuracy.item())\n",
    "        return self.val_acc\n",
    "    \n",
    "    \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, train, target):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.train = train\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.train[index], self.target[index]    \n",
    "    \n",
    "# Download MNIST dataset if you dont already have one\n",
    "def download_mnist_datasets():\n",
    "    train_data = datasets.MNIST(\n",
    "        root = \"data\",\n",
    "        download = True,\n",
    "        train = True,\n",
    "        transform = ToTensor()\n",
    "    )\n",
    "    \n",
    "    print (train_data)\n",
    "    \n",
    "    validation_data = datasets.MNIST(\n",
    "        root =\"data\",\n",
    "        download= True,\n",
    "        train = False,\n",
    "        transform = ToTensor()\n",
    "    )\n",
    "    \n",
    "    return train_data, validation_data\n",
    "\n",
    "    \n",
    "def train_one_epoch(model, data_loader, loss_fn, optimiser, device, val_input, val_target):\n",
    "    \n",
    "    for inputs, targets in data_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Calculate loss\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        # Back propagate loss and update weights\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    val_acc = model.validation_accuracy(val_input, val_target)\n",
    "    print (f\"Loss: {loss.item()} | val_accuracy: {val_acc}\")\n",
    "    logger.info(f\"val_accuracy: {val_acc}\")\n",
    "    # return loss.item()\n",
    "\n",
    "    \n",
    "def train_epochs(model, data_loader, loss_fn, optimiser, device, epochs, val_input, val_target):\n",
    "    for i in range(epochs):\n",
    "        print (f\"Epoch {i+1}\")\n",
    "        logger.info(f\"Epoch: {i+1}\")\n",
    "        train_one_epoch(model, data_loader, loss_fn, optimiser, device, val_input, val_target)\n",
    "        print (\"------------------------------------------------------\")\n",
    "    print (\"Training completed\")\n",
    "    \n",
    "        \n",
    "def train(base_directory, train_path, validation_path, epochs=50, batch_size=32, learning_rate = 0.001):\n",
    "    \n",
    "#     # Download MNIST dataset if you dont already have one\n",
    "#     train_data, validation_data = download_mnist_datasets()\n",
    "#     print ('downloaded')\n",
    "    \n",
    "#     # Create data loader for the train set\n",
    "#     train_data_loader = DataLoader(train_data, batch_size)\n",
    "#     for inputs, targets in train_data_loader:\n",
    "#         print (inputs.dtype)\n",
    "#         print (targets.dtype)\n",
    "\n",
    "    # Load dataset\n",
    "    X = pd.read_csv(Path(train_path) / \"train.csv\")\n",
    "    y = X[X.columns[-1]]\n",
    "    X.drop(X.columns[-1], axis=1, inplace=True)\n",
    "    X_train = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y.values, dtype=torch.int64)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    \n",
    "    testmnist = CustomDataset(X_train, y_train)\n",
    "    dataloader = DataLoader(testmnist, batch_size=32, shuffle = False)\n",
    "    # for inputs, targets in dataloader:\n",
    "    #     print (inputs.shape)\n",
    "    #     print(\"-------------------------------------------------\")\n",
    "    #     print(targets.shape)\n",
    "    #     print(\" ================================================= \")\n",
    "    \n",
    "    X_val = pd.read_csv(Path(validation_path) / \"validation.csv\")\n",
    "    y_val = X_val[X_val.columns[-1]]\n",
    "    X_val.drop(X_val.columns[-1], axis=1, inplace=True)\n",
    "    X_validation = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_validation = torch.tensor(y_val.values, dtype=torch.int64)\n",
    "\n",
    "\n",
    "    # Build model\n",
    "    # Set device for training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Net().to(device)\n",
    "    \n",
    "    # print (X_train.dtype)\n",
    "    # print (model.weight.dtype)\n",
    "    \n",
    "    # Instantiate loss function & optimiser\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.Adam(model.parameters(),\n",
    "                                lr = learning_rate)\n",
    "    \n",
    "    # Train Model\n",
    "    train_epochs(model, dataloader, loss_fn, optimiser, device, epochs, X_validation, y_validation)\n",
    "    # train_one_epoch(model, dataloader, loss_fn, optimiser, device)\n",
    "    \n",
    "    # # Store model\n",
    "    # torch.save(model.state_dict(), Path(base_directory)/\"model/\")\n",
    "    # print (\"Model trained and stored\")\n",
    "    \n",
    "    # Store model\n",
    "    model_dir = Path(base_directory) / \"model\" / \"001\"\n",
    "    S3_path = \"s3://mlschool01//root/ml.school/mnist\"\n",
    "    # model_dir = Path(S3_path) / \"model\" / \"001\"\n",
    "    \n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'wb') as f:\n",
    "        torch.save(model.state_dict(), f)\n",
    "        # TEST UPLOAD OF THE MODEL TO S3\n",
    "        # s3 = boto3.resource('s3')\n",
    "        # s3.Bucket(\"mlschool01\").upload_file(os.path.join(model_dir, 'model.pth'), \"root/ml.school/mnist/model/model.tar.gz\")\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Any hyperparameters provided by the training job are passed to the entry point\n",
    "    # as script arguments. SageMaker will also provide a list of special parameters\n",
    "    # that you can capture here. Here is the full list: \n",
    "    # https://github.com/aws/sagemaker-training-toolkit/blob/master/src/sagemaker_training/params.py\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--base_directory\", type=str, default=\"/opt/ml/\")\n",
    "    parser.add_argument(\"--train_path\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\", None))\n",
    "    parser.add_argument(\"--validation_path\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\", None))\n",
    "    parser.add_argument(\"--epochs\", type=int, default=3)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.01)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    # PRODUCTION\n",
    "    train(\n",
    "        base_directory=args.base_directory,\n",
    "        train_path=args.train_path,\n",
    "        validation_path=args.validation_path,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate = args.learning_rate\n",
    "    )\n",
    "    \n",
    "    # # LOCAL TESTING\n",
    "    # base_dir = Path(os.getcwd()) / \"opt/ml/processing/\"\n",
    "    # train_path = Path(base_dir) / \"train/\"\n",
    "    # validation_path = Path(base_dir) / \"validation/\"\n",
    "    # train(\n",
    "    #     base_directory= base_dir,\n",
    "    #     train_path= train_path,\n",
    "    #     validation_path= validation_path,\n",
    "    #     epochs=args.epochs,\n",
    "    #     batch_size=args.batch_size\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850f244-0e80-4426-a41f-6917fd04f9a9",
   "metadata": {},
   "source": [
    "## Testing training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "829bdddc-3924-4f03-af57-c783a5137b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from preprocessor import preprocess\n",
    "# from train import train\n",
    "\n",
    "\n",
    "# with tempfile.TemporaryDirectory() as directory:\n",
    "#     # First, we preprocess the data and create the \n",
    "#     # dataset splits.\n",
    "#     preprocess(\n",
    "#         base_dir=directory, \n",
    "#         data_filepath = Path(DATASET_FOLDER) /  \"mnist_train.csv\"\n",
    "#     )\n",
    "\n",
    "#     # Then, we train a model using the train and \n",
    "#     # validation splits.\n",
    "#     train(\n",
    "#         base_directory=directory, \n",
    "#         train_path=Path(directory) / \"train\", \n",
    "#         validation_path=Path(directory) / \"validation\",\n",
    "#         epochs=5\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f548441-1cf6-4f4f-8392-777a40e1db2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training and Tuning switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1d0cee9-c07e-433e-9136-92d0cd3dedca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_TUNING_STEP = True\n",
    "# USE_TUNING_STEP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8a0be-d3fb-4de3-9d87-c9eecf484bad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f11d8c1b-4a42-41d5-8a9c-05af43675495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\":0.001,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=f\"{MNIST_FOLDER}/train.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version=\"1.13.1\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    script_mode=True,\n",
    "    disable_profiler=True,\n",
    "    role=role,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83da99be-7712-42f6-aad5-85754d1d9975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_step = TrainingStep(\n",
    "    name=\"training\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e897bd-9911-43dd-8562-4d874749fe3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up tuning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cb57125-fcca-4e39-8ce3-ce1b77dd1c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(10, 50),\n",
    "    \"learning_rate\":ContinuousParameter(0.001,0.004)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"val_accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}]\n",
    "    \n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    objective_type=objective_type,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "116c19c9-216a-4868-91a6-e3a31d6e99b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_step = TuningStep(\n",
    "    name = \"tuning\",\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2cc7887-94a4-46fd-8774-985e3828b30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session2_pipeline = Pipeline(\n",
    "    name=\"mnist-session2-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b4e7d5e-070b-44a4-8bff-a4236c414f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session2_pipeline.upsert(role_arn=role)\n",
    "# execution = session2_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743adb47-5f41-4bff-9d8d-bcbf18ce0e0a",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8914e613-7d9e-40d6-9a3d-9dc1628fed02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlowProcessor\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba783bc-ce12-4f60-81a5-937ca883afb0",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d5a1207-8684-4568-b6cc-56aa13cc344d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /root/ml.school/mnist/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MNIST_FOLDER}/evaluation.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "# from tensorflow import keras\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## LOCAL TESTING\n",
    "# BASE_DIR = '/root/ml.school/mnist/opt/ml/processing'\n",
    "# MODEL_PATH = Path(BASE_DIR) / \"model/\"\n",
    "# TEST_PATH = Path(BASE_DIR) / \"test/\"\n",
    "# OUTPUT_PATH = Path(BASE_DIR) / \"evaluation/\"\n",
    "\n",
    "## ACTUAL USE\n",
    "MODEL_PATH = \"/opt/ml/processing/model/\"\n",
    "TEST_PATH = \"/opt/ml/processing/test/\"\n",
    "OUTPUT_PATH = \"/opt/ml/processing/evaluation/\"\n",
    "\n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        # self.accuracy = MulticlassAccuracy(num_classes=10)\n",
    "        self.val_acc = 0\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.flatten(input_data)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    \n",
    "    def validation_accuracy(self, inputs, vals):\n",
    "        pred = self(inputs).detach().numpy()\n",
    "        predictions = np.argmax(pred, axis=-1)\n",
    "        self.val_acc = accuracy_score(vals, predictions)\n",
    "        # self.log('val_acc', self.accuracy.item())\n",
    "        return self.val_acc\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = Net()\n",
    "    print (model_dir)\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    return model\n",
    "    \n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    ## FOR LOCAL TESTING\n",
    "    # with tarfile.open(Path(model_path) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "    #     tar.add(Path(model_path) / \"001\", arcname=\"001\")\n",
    "    \n",
    "    # The first step is to extract the model package provided\n",
    "    # by SageMaker.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    # We can now load the model from disk.\n",
    "    # model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    # model_dir = Path(model_path) / \"model\" / \"001\"\n",
    "    model_dir = Path(model_path) / \"001\"\n",
    "    model = model_fn(model_dir)\n",
    "    # model = torch.load(Path(model_path) / \"001\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test[X_test.columns[-1]]\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    # Convert dataframe to tensors\n",
    "    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.int64)\n",
    "    \n",
    "    # Getting validation accuracy\n",
    "    accuracy = model.validation_accuracy(X_test, y_test)\n",
    "    pred = model(X_test).detach().numpy()\n",
    "    predictions = np.argmax(pred, axis=-1)\n",
    "    print(f\"Validation accuracy: {accuracy}\")\n",
    "    print (f\"Prediction {predictions}\")\n",
    "\n",
    "    # Add the accuracy of the model to our evaluation report.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # Save the evaluation report to the output path.\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=MODEL_PATH, \n",
    "        test_path=TEST_PATH,\n",
    "        output_path=OUTPUT_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386aec10-27d8-4e29-a770-e252dd70a13a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7e6bee9-a0c4-4245-a18b-a7c7903f92c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from preprocessor import preprocess\n",
    "# from train import train\n",
    "# from evaluation import evaluate\n",
    "\n",
    "\n",
    "# with tempfile.TemporaryDirectory() as directory:\n",
    "#     # First, we preprocess the data and create the \n",
    "#     # dataset splits.\n",
    "#     preprocess(\n",
    "#         base_dir=directory, \n",
    "#         # data_filepath=LOCAL_FILEPATH\n",
    "#         data_filepath=Path(DATASET_FOLDER) /  \"mnist_train.csv\"\n",
    "#     )\n",
    "\n",
    "#     # Then, we train a model using the train and \n",
    "#     # validation splits.\n",
    "#     train(\n",
    "#         base_directory=directory, \n",
    "#         train_path=Path(directory) / \"train\", \n",
    "#         validation_path=Path(directory) / \"validation\",\n",
    "#         epochs=1\n",
    "#     )\n",
    "    \n",
    "#     # After training a model, we need to prepare a package just like\n",
    "#     # SageMaker would. This package is what the evaluation script is\n",
    "#     # expecting as an input.\n",
    "#     with tarfile.open(Path(directory) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "#         tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "#     print (f\"directory : {directory}\")\n",
    "    \n",
    "#     # We can now call the evaluation script.\n",
    "#     evaluate(\n",
    "#         model_path=directory, \n",
    "#         test_path=Path(directory) / \"test\",\n",
    "#         output_path=Path(directory) / \"evaluation\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b8023-c60b-44a3-aabe-b8696c642c05",
   "metadata": {},
   "source": [
    "## Pipeline configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ee8460c-f32a-4a4d-8c84-443284bb93ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_destination = ParameterString(\n",
    "    name=\"evaluation_destination\",\n",
    "    default_value=f'{S3_FILEPATH}/evaluation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2c4aad4-dfd3-413d-bd94-eafa0e4f84d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://mlschool01//root/ml.school/mnist'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_FILEPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c64a0-e08f-407e-8023-139af138f833",
   "metadata": {},
   "source": [
    "## Setting up processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc8e53c3-208e-4b98-831a-4e8a549c4b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialize the PyTorchProcessor\n",
    "pytorch_processor = PyTorchProcessor(\n",
    "    framework_version='1.13.1',\n",
    "    role=role,\n",
    "    instance_type='ml.t3.medium',\n",
    "    instance_count=1,\n",
    "    base_job_name='mnist-evaluation-processor',\n",
    "    py_version=\"py39\",\n",
    ")\n",
    "\n",
    "pytorch_processor.framework_entrypoint_command = [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad035e5-8837-446f-8ec6-5d4f2593bd19",
   "metadata": {},
   "source": [
    "## Configure model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "863380c2-ec24-4095-9b97-fa7b188db4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the input in case we want to use the best model generated\n",
    "# by the Tuning Step.\n",
    "tuning_model_input = ProcessingInput(\n",
    "    source=tuning_step.get_top_model_s3_uri(\n",
    "        top_k=1, \n",
    "        s3_bucket=sagemaker_session.default_bucket()\n",
    "    ),\n",
    "    destination=\"/opt/ml/processing/model\",\n",
    ")\n",
    "\n",
    "# This is the input in case we want to use the trained model\n",
    "# from the Training Step.\n",
    "training_model_input = ProcessingInput(\n",
    "    source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    destination=\"/opt/ml/processing/model\"\n",
    ")\n",
    "\n",
    "# We can now select the appropriate input depending on which step\n",
    "# we are using.\n",
    "model_input = tuning_model_input if USE_TUNING_STEP else training_model_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae0c55-b060-4c76-be1e-27aae3756021",
   "metadata": {},
   "source": [
    "## Set up processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d96f67f-b6c6-4fa3-b0b6-7d95001ea743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ml.school/mnist\n"
     ]
    }
   ],
   "source": [
    "print (MNIST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2c2312d-f0eb-4b56-b3d3-c0b66ee246fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want to map the evaluation report that we generate inside\n",
    "# the evaluation script so we can later reference it.\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "\n",
    "# Notice how this step uses the model generated by the tuning or training\n",
    "# step, and the test set generated by the preprocessing step.\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"evaluation\",\n",
    "    processor=pytorch_processor,\n",
    "    inputs=[\n",
    "        model_input,\n",
    "        ProcessingInput(\n",
    "            source=preprocess_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=evaluation_destination),\n",
    "    ],\n",
    "    code=f\"{MNIST_FOLDER}/evaluation.py\",\n",
    "    # code=f\"{S3_FILEPATH}/evaluation.py\",\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524dd61-d420-426b-a419-36e7d3fba2b8",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d58f3d36-3f3a-4f98-bf63-b5b78fe5dadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session3_pipeline = Pipeline(\n",
    "    name=\"mnist-session3-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        evaluation_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step,\n",
    "        evaluation_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "166079d1-27a1-424f-aa5c-dbf82c448ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session3_pipeline.upsert(role_arn=role)\n",
    "# execution = session3_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b55047-1542-4047-a6f5-f744100a1062",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e8c5e-80a3-4f03-808e-4892bc6995f0",
   "metadata": {},
   "source": [
    "## Approval and Threshold configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb20a423-c845-4503-9676-77ae35242da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4cfc429-a544-47cf-a29c-f95304670569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_approval_status = ParameterString(\n",
    "    name=\"model_approval_status\", \n",
    "    default_value=\"Approved\"\n",
    ")\n",
    "\n",
    "accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold\", \n",
    "    default_value=0.60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b9264-09c3-470b-ac4e-7dd6cffdccaa",
   "metadata": {},
   "source": [
    "## Configurin Model Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5dad3e8-be21-4285-99eb-4b76f344c513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the model data in case we want to use the best model generated\n",
    "# by the Tuning Step.\n",
    "tuning_model_data = tuning_step.get_top_model_s3_uri(\n",
    "    top_k=1, \n",
    "    s3_bucket=sagemaker_session.default_bucket()\n",
    ")\n",
    "\n",
    "# This is the model data in case we want to use the trained model\n",
    "# from the Training Step.\n",
    "training_model_data = training_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "# We can now select the appropriate model data depending on which step\n",
    "# we are using.\n",
    "model_data = tuning_model_data if USE_TUNING_STEP else training_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcf8fa-d057-4b5e-b1c5-0461ca61b507",
   "metadata": {},
   "source": [
    "## Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5404819-4acb-4537-bcce-2316b85e8a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.13.1\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    entry_point = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8253dcda-27c0-4e24-99c4-edcc01fc055a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S3Uri': ParameterString(name='evaluation_destination', parameter_type=<ParameterTypeEnum.STRING: 'String'>, default_value='s3://mlschool01//root/ml.school/mnist/evaluation'), 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}\n"
     ]
    }
   ],
   "source": [
    "print (evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b77e35-2e98-4b8a-b52e-f9cdd2903f3e",
   "metadata": {},
   "source": [
    "## Setting up Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8626ce9e-9967-4447-ae15-6b16971b4e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on=\"/\", values=[\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\n",
    "            \"evaluation.json\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88682a-7733-4ecd-a0a2-adfb07bb297d",
   "metadata": {},
   "source": [
    "## Set up model step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da008472-16cb-4a49-81da-f17e29120dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:258: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = \"mnist-model-package-group\"\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=model_approval_status,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.13.1\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4714e73f-688c-4c49-9afa-716edd346f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml.t3.medium\n",
    "# ml.m5.large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f29f07-caf9-4ef1-9d5f-9d6de205607f",
   "metadata": {},
   "source": [
    "## Set up condition step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e530290c-1fa4-4d3f-89e7-58cad4c174d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\"\n",
    "    ),\n",
    "    right=accuracy_threshold\n",
    ")\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \", \n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\", \n",
    "            accuracy_threshold\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c9766bb-44d5-4510-a1af-d0d91ccd292b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session4_pipeline = Pipeline(\n",
    "    name=\"mnist-session4-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step, \n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46850043-dbb7-4762-9573-a555d6621428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session4_pipeline.upsert(role_arn=role)\n",
    "# execution = session4_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1908b588-920f-49cc-8b51-4bf01bbeb761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import boto3\n",
    "# key = 'arn:aws:kms:ap-southeast-1:972688410650:key/fcc541cf-7260-42a6-8135-38f301b62c98'\n",
    "# s3 = boto3.resource('s3')\n",
    "\n",
    "# obj = s3.Object(BUCKET, key)\n",
    "# data = json.load(obj.get()['Body']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c27ba6d-ed9e-4454-b7f3-cf4312ea69a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest approved model package: arn:aws:sagemaker:ap-southeast-1:972688410650:model-package/mnist-model-package-group/2\n"
     ]
    }
   ],
   "source": [
    "def get_latest_approved_model_package(model_package_group_name):\n",
    "    \"\"\"\n",
    "    Returns the latest approved model package registered under the \n",
    "    specified model package group.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # We can use the boto3 SageMaker's API to list the existing\n",
    "        # model packages with the specified name. We only care about\n",
    "        # approved models.\n",
    "        response = sagemaker_client.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            MaxResults=100,\n",
    "        )\n",
    "        approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "        if len(approved_packages) == 0:\n",
    "            print(f\"No approved model pacakages for \\\"{model_package_group_name}\\\"\")\n",
    "            return None\n",
    "\n",
    "        # At this point we identified the latest approved model,\n",
    "        # so we can return it.\n",
    "        print(f\"Latest approved model package: {approved_packages[0]['ModelPackageArn']}\")\n",
    "        return approved_packages[0]\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(e.response[\"Error\"][\"Message\"])\n",
    "        raise Exception(e.response[\"Error\"][\"Message\"])\n",
    "        \n",
    "\n",
    "# We can now use the function to get the latest approved model from the Model Registry.\n",
    "approved_model_package = get_latest_approved_model_package(model_package_group_name)\n",
    "\n",
    "model_description = None\n",
    "if approved_model_package:\n",
    "    approved_model_package_arn = approved_model_package[\"ModelPackageArn\"]\n",
    "\n",
    "    model_description = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=approved_model_package_arn\n",
    "    )\n",
    "\n",
    "# model_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9485b1b9-4ab5-4699-ba9d-7c4393686410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TESTING OF ENDPOINT BUT THIS DIDNT WORK. CANT CALL PYTORCH MODEL PROPERLY WITH SAGEMAKER\n",
    "# model_package = ModelPackage(\n",
    "#     model_package_arn=approved_model_package_arn, \n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     role=role, \n",
    "# )\n",
    "\n",
    "# endpoint_name = \"mnist-endpoint\"\n",
    "\n",
    "# model_package.deploy(\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     initial_instance_count=1, \n",
    "#     instance_type=\"ml.m5.large\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bba706-95d1-4a85-bb18-c8d2c0c232ad",
   "metadata": {},
   "source": [
    "## Trying to create custom mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14ee9380-9b5b-44ee-8da2-94e87fec3065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31eedd80-0e19-42ff-9422-35cd48ef26c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73, 239, 10, 205, 216, 211, 24, 93, 112, 76, 163, 134, 249, 156, 100, 78, 244, 47, 42, 149, 54, 250, 129, 2, 131, 148, 241, 188, 115, 70, 67, 12, 209, 89, 194, 210, 181, 214, 96, 175, 224, 205, 9, 192, 83, 46, 15, 123, 117, 66, 75, 142, 7, 57, 77, 113, 19, 216, 155, 178, 183, 10, 46, 244, 140, 235, 168, 54, 207, 252, 116, 198, 133, 221, 60, 240, 134, 114, 166, 93, 8, 8, 71, 82, 224, 155, 50, 213, 137, 217, 135, 34, 131, 14, 50, 208, 21, 119, 128, 250, 56, 173, 6, 191, 248, 177, 222, 21, 19, 103, 81, 170, 247, 138, 82, 211, 65, 14, 151, 94, 157, 135, 207, 59, 34, 121, 57, 248, 31, 252, 157, 14, 104, 99, 90, 82, 183, 136, 189, 11, 228, 4, 2, 218, 97, 139, 207, 9, 72, 4, 105, 162, 51, 86, 26, 117, 181, 153, 205, 224, 67, 196, 233, 233, 32, 13, 124, 134, 119, 180, 159, 199, 160, 29, 100, 34, 104, 193, 153, 16, 34, 18, 123, 205, 118, 31, 229, 239, 182, 167, 194, 200, 208, 91, 75, 206, 86, 162, 109, 44, 224, 251, 236, 144, 23, 166, 201, 237, 147, 108, 12, 70, 111, 213, 6, 182, 165, 207, 16, 228, 171, 138, 242, 141, 185, 207, 234, 72, 27, 62, 182, 43, 108, 75, 57, 199, 59, 141, 79, 110, 149, 158, 49, 92, 135, 32, 142, 198, 64, 135, 51, 142, 79, 202, 53, 12, 98, 67, 53, 64, 244, 134, 64, 32, 29, 127, 239, 60, 104, 81, 126, 124, 228, 201, 206, 139, 72, 106, 25, 192, 3, 207, 89, 115, 51, 250, 215, 176, 182, 135, 208, 65, 69, 117, 25, 114, 201, 127, 149, 15, 235, 25, 11, 107, 107, 11, 172, 166, 112, 93, 53, 219, 28, 191, 153, 252, 120, 122, 150, 243, 212, 87, 109, 177, 93, 60, 156, 4, 102, 150, 11, 185, 200, 216, 165, 80, 91, 151, 222, 251, 103, 240, 57, 245, 151, 84, 174, 23, 232, 225, 107, 160, 23, 23, 32, 24, 142, 210, 19, 210, 143, 211, 63, 36, 252, 219, 62, 242, 93, 224, 87, 80, 199, 156, 50, 33, 49, 133, 23, 248, 148, 90, 135, 155, 155, 37, 105, 135, 252, 39, 5, 166, 49, 225, 192, 29, 28, 77, 192, 20, 162, 129, 109, 81, 218, 156, 251, 180, 121, 167, 240, 34, 69, 242, 193, 76, 128, 94, 246, 164, 207, 109, 43, 37, 90, 169, 61, 247, 83, 217, 44, 182, 15, 239, 172, 94, 209, 167, 148, 78, 247, 73, 198, 172, 175, 241, 41, 195, 141, 131, 10, 112, 5, 105, 208, 82, 165, 33, 81, 142, 62, 9, 250, 127, 130, 234, 197, 41, 147, 35, 212, 245, 192, 244, 206, 230, 67, 201, 199, 135, 58, 251, 183, 112, 19, 139, 92, 12, 92, 66, 77, 39, 171, 133, 53, 246, 130, 80, 163, 168, 50, 22, 139, 141, 210, 230, 148, 250, 246, 129, 187, 9, 147, 123, 116, 39, 154, 165, 126, 202, 168, 155, 254, 250, 239, 39, 244, 224, 162, 161, 222, 145, 188, 89, 181, 12, 28, 162, 68, 22, 112, 175, 89, 118, 160, 30, 193, 46, 226, 105, 254, 85, 165, 99, 39, 66, 205, 9, 106, 39, 86, 197, 243, 163, 56, 220, 158, 8, 224, 61, 141, 14, 91, 162, 8, 174, 207, 39, 226, 25, 190, 163, 78, 253, 136, 246, 9, 4, 219, 126, 165, 227, 151, 247, 153, 102, 99, 231, 21, 57, 240, 67, 154, 112, 32, 32, 63, 177, 18, 36, 65, 225, 235, 217, 228, 149, 10, 46, 165, 28, 131, 219, 32, 15, 179, 64, 117, 141, 50, 203, 138, 51, 154, 253, 222, 236, 172, 172, 214, 224, 156, 95, 201, 154, 171, 178, 125, 245, 217, 14, 75, 133, 139, 58, 203, 222, 67, 60, 170, 130, 59, 82, 246, 103, 174, 127, 207, 110, 188, 46, 137, 70, 248, 20, 169, 216, 70, 62, 55, 223, 228, 169, 24, 201, 109, 91, 23, 110, 108, 227, 196, 24, 54, 107, 173, 140, 75, 180, 219, 170, 248, 156, 145, 146, 174, 66, 72, 244, 212, 213, 88, 177, 241, 216, 67, 186, 150, 25, 40, 196, 133, 99, 108, 211, 246, 20, 8, 17, 158, 28, 48, 23, 228, 249, 33, 138, 166, 81, 121, 75, 59, 60, 148, 137, 48, 219, 51, 159, 148, 103, 43, 42, 92, 245, 244, 252, 108, 160, 152, 205, 87, 127, 210, 191, 166, 248, 169, 230, 14, 193, 59, 113, 35, 200, 194, 128, 156, 122, 117, 158, 55, 40, 95, 216\n"
     ]
    }
   ],
   "source": [
    "payload = \"\"\n",
    "for i in range(28 * 28):\n",
    "    if (i != 783):\n",
    "        payload = payload + str(random.randint(0,254)) + \", \"\n",
    "    else:\n",
    "        payload = payload + str(random.randint(0,254))\n",
    "print (payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7175d2c3-1ee6-4c53-9252-31429a5bcafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03a334-7795-4694-820c-57558133ddf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e760872-adc8-483c-91df-2c4d9bf1f7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.workflow.lambda_step import LambdaStep, LambdaOutput, LambdaOutputTypeEnum\n",
    "from sagemaker.workflow.parameters import ParameterBoolean\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.s3 import S3Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb822057-a967-44a5-851d-a56d13ee8f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CODE_FOLDER = Path(MNIST_FOLDER) / \"code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f73fcd5-a414-4c64-9991-2e96e2d9ff9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /root/ml.school/mnist/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $CODE_FOLDER/inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "from pickle import load\n",
    "from pathlib import Path\n",
    "\n",
    "PIPELINE_FILE = Path(\"/tmp\") / \"pipeline.pkl\"\n",
    "\n",
    "# By default, we will read the S3 location of the Scikit-Learn\n",
    "# pipeline from an environment variable that we'll configure\n",
    "# when registering the model.\n",
    "PIPELINE_S3_LOCATION = os.environ.get(\"PIPELINE_S3_LOCATION\", None)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "def handler(data, context, model_dir, pipeline_s3_location=PIPELINE_S3_LOCATION):\n",
    "    \"\"\"\n",
    "    This is the entrypoint that will be called by SageMaker when the endpoint\n",
    "    receives a request. You can see more information at \n",
    "    https://github.com/aws/sagemaker-tensorflow-serving-container.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Handling endpoint request\")\n",
    "    download_pipeline(pipeline_s3_location)\n",
    "    input_data = input_fn(data)\n",
    "    model = model_fn(model_dir)\n",
    "    predictions = predict_fn(input_data, model)\n",
    "    output_json = output_fn(predictions)\n",
    "    \n",
    "    return output_json\n",
    "\n",
    "\n",
    "def download_pipeline(pipeline_s3_location):\n",
    "    \"\"\"\n",
    "    This function will download the Scikit-Learn pipeline from S3\n",
    "    if it doesn't already exist. We need the pipeline to pre-process\n",
    "    the data before we run it through the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_parts = pipeline_s3_location.split('/', 3)\n",
    "    bucket = s3_parts[2]\n",
    "    key = s3_parts[3]\n",
    "    \n",
    "    if not PIPELINE_FILE.exists():\n",
    "        s3.Bucket(bucket).download_file(f\"{key}/pipeline.pkl\", str(PIPELINE_FILE))\n",
    "    \n",
    "    print (\"Pipeline Downloaded\")\n",
    "    \n",
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        # self.accuracy = MulticlassAccuracy(num_classes=10)\n",
    "        self.val_acc = 0\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.flatten(input_data)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "    \n",
    "    def validation_accuracy(self, inputs, vals):\n",
    "        pred = self(inputs).detach().numpy()\n",
    "        predictions = np.argmax(pred, axis=-1)\n",
    "        self.val_acc = accuracy_score(vals, predictions)\n",
    "        # self.log('val_acc', self.accuracy.item())\n",
    "        return self.val_acc\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info('Loading model')\n",
    "    model = Net()\n",
    "    print (model_dir)\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    logger.info('Successfully loaded model')\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, content_type = 'application/json'):\n",
    "    logger.info('Deserializing input data')\n",
    "    if content_type == 'image/png':\n",
    "        \n",
    "        # Convert image to tensor\n",
    "        image = Image.open(Path(os.getcwd()) / \"sample_image.png\")\n",
    "        \n",
    "        #Define transform to resize image to 28x28 and convert PIL image to Torch tensor\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(size = (28,28)),\n",
    "            transforms.PILToTensor()\n",
    "        ])\n",
    "        img_tensor = image_transform(image)\n",
    "        img_tensor.to(dtype = torch.int64)\n",
    "        \n",
    "        return img_tensor\n",
    "    \n",
    "    elif content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        url = input_data['url']\n",
    "        logger.info(f'Image url: {url}')\n",
    "        image = Image.open(requests.get(url, stream=True).raw)\n",
    "        \n",
    "        #Define transform to resize image to 28x28 and convert PIL image to Torch tensor\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(size = (28,28)),\n",
    "            transforms.PILToTensor()\n",
    "        ])\n",
    "        img_tensor = image_transform(image)\n",
    "        img_tensor.to(dtype = torch.int64)\n",
    "        \n",
    "        return img_tensor\n",
    "    \n",
    "    raise Exception(f'Requested unsupported ContentType in content_type {content_type}')\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    logger.info('Generating prediction')\n",
    "    if torch.cuda.is_available():\n",
    "        input_data = input_data.view(1,28,28).cuda()\n",
    "    else:\n",
    "        input_data = input_data.view(1,28,28)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(input_data).detach().numpy()\n",
    "        predictions = np.argmax(out, axis=-1)\n",
    "        return predictions\n",
    "    \n",
    "def output_fn(prediction_outout, accept = 'application/json'):\n",
    "    logger.info('Serializing generated output')\n",
    "    results = []\n",
    "    for i in range(len(prediction_output)):\n",
    "        results.append(prediction_output[i])\n",
    "    if accept == 'application/json':\n",
    "        return json.dumps(result), accept\n",
    "    raise Exception(f'Requested unsupported content type in accept: {accept}')\n",
    "\n",
    "# # FOR LOCAL TESTING || JSON CONTAINING URL OF IMAGE\n",
    "# url_dict = {\"url\" : \"https://conx.readthedocs.io/en/latest/_images/MNIST_57_0.png\"}\n",
    "# json_object = json.dumps(url_dict)\n",
    "\n",
    "# input_fn(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7feafbf1-1bd3-4b7d-9009-128546580947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /root/ml.school/mnist/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $CODE_FOLDER/requirements.txt\n",
    "\n",
    "numpy==1.19.5\n",
    "pandas==1.2.5\n",
    "scikit-learn==0.23.2\n",
    "torch==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85580ce5-d79c-4170-905b-b19ff71280c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c96f21d-47f9-42a3-a05f-481b7d64d7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pytorch_model = PyTorchModel(model_data='s3://mlschool01/root/ml.school/mnist/model/model.tar.gz', role=role, entry_point='inference.py', framework_version='1.13.1', py_version=\"py39\", source_dir=str(CODE_FOLDER))\n",
    "# predictor = pytorch_model.deploy(instance_type='ml.m5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfdf04-a066-420e-8897-63ecc2550a6d",
   "metadata": {},
   "source": [
    "### Registering model after writing inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ca34497-9aca-4bdb-b8c2-a0d199d8e4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.13.1\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    env={\n",
    "        \"PIPELINE_S3_LOCATION\": preprocessor_destination,\n",
    "    },\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    entry_point = \"inference.py\",\n",
    "    source_dir=str(CODE_FOLDER),\n",
    ")\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=model_approval_status,\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.13.1\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03381254-5ac4-4a5c-bed4-310de36d2e6a",
   "metadata": {},
   "source": [
    "### Data capture configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2dcb5b7-accf-4b45-b5e6-136741dce75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_capture_enabled = ParameterBoolean(\n",
    "    name=\"data_capture_enabled\",\n",
    "    default_value=True,\n",
    ")\n",
    "\n",
    "data_capture_percentage = ParameterInteger(\n",
    "    name=\"data_capture_percentage\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "data_capture_destination = ParameterString(\n",
    "    name=\"data_capture_destination\",\n",
    "    default_value=f\"{S3_FILEPATH}/monitoring/data-capture\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee186436-ef91-4fb4-89bc-59d39db09ce0",
   "metadata": {},
   "source": [
    "### Deploying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d539eab0-7d7f-43ca-8b03-a65fa22ec97d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /root/ml.school/mnist/lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $MNIST_FOLDER/lambda.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    model_package_arn = event[\"model_package_arn\"]\n",
    "    model_name = event[\"model_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    data_capture_enabled = event[\"data_capture_enabled\"]\n",
    "    data_capture_percentage = event[\"data_capture_percentage\"]\n",
    "    data_capture_destination = event[\"data_capture_destination\"]\n",
    "    role = event[\"role\"]\n",
    "    \n",
    "    \n",
    "    # The first step is to create a new model. We will use the\n",
    "    # ARN of the model we registered.\n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name, \n",
    "        ExecutionRoleArn=role, \n",
    "        Containers=[{\n",
    "            \"ModelPackageName\": model_package_arn\n",
    "        }] \n",
    "    )\n",
    "\n",
    "    # Then, we need to create an Endpoint Configuration.\n",
    "    # Here is where we specify the hardware we need for the\n",
    "    # endpoint and the Data Capture configuration. \n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.large\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        DataCaptureConfig={\n",
    "            \"EnableCapture\": data_capture_enabled,\n",
    "            \"InitialSamplingPercentage\": data_capture_percentage,\n",
    "            \"DestinationS3Uri\": data_capture_destination,\n",
    "            \"CaptureOptions\": [\n",
    "                {\n",
    "                    'CaptureMode': \"Input\"\n",
    "                },\n",
    "                {\n",
    "                    'CaptureMode': \"Output\"\n",
    "                },\n",
    "            ],\n",
    "            \"CaptureContentTypeHeader\": {\n",
    "                \"JsonContentTypes\": [\n",
    "                    \"application/json\",\n",
    "                    \"application/octect-stream\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Finally, we can create the new Endpoint using the\n",
    "    # Endpoint Configuration we created above.\n",
    "    sagemaker.create_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Endpoint deployed successfully\"),\n",
    "        \"model_name\": model_name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6ed61-d35a-488f-9d4e-4ab53f9d2a67",
   "metadata": {},
   "source": [
    "### Creating Lamda Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dfd812b9-adb4-40b9-af3c-a4c23f3ce057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam_client.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description=\"Lambda Pipeline Role\"\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "            RoleName=role_name\n",
    "        )\n",
    "\n",
    "        return role_arn\n",
    "\n",
    "    except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "        response = iam_client.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']\n",
    "    \n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-pipeline-role\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18397cb-a3f9-4988-abf4-c353e4b138d2",
   "metadata": {},
   "source": [
    "### Set up Lambda Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f12b1e10-dab2-4a09-863e-7bd7fd4a5121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_name = f\"deploy-endpoint-fn-{time.strftime('%m%d%H%M%S', time.localtime())}\"\n",
    "endpoint_name = \"mnist-endpoint\"\n",
    "\n",
    "deploy_step = LambdaStep(\n",
    "    name=\"deploy\",\n",
    "    lambda_func=Lambda(\n",
    "        function_name=function_name,\n",
    "        execution_role_arn=lambda_role,\n",
    "        script=str(MNIST_FOLDER / \"lambda.py\"),\n",
    "        handler=\"lambda.lambda_handler\",\n",
    "        timeout=600,\n",
    "        memory_size=3008,\n",
    "    ),\n",
    "    inputs={\n",
    "        # We can use the timestamp_signature pipeline parameter\n",
    "        # to add a suffix to the model and the endpoint configuration\n",
    "        # and avoid name collisions.\n",
    "        \"model_name\": Join(on=\"-\", values=[\"mnist-model\", timestamp_signature]),\n",
    "        \"endpoint_config_name\": Join(on=\"-\", values=[\"mnist-endpoint-config\", timestamp_signature]),\n",
    "\n",
    "        # We use the ARN of the model we registered to\n",
    "        # deploy it to the endpoint.\n",
    "        \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"data_capture_enabled\": data_capture_enabled,\n",
    "        \"data_capture_percentage\": data_capture_percentage,\n",
    "        \"data_capture_destination\": data_capture_destination,\n",
    "        \"role\": role,\n",
    "    },\n",
    "    outputs=[\n",
    "        LambdaOutput(output_name=\"model_name\", output_type=LambdaOutputTypeEnum.String)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4816fd0e-373b-4375-9d36-c45cdaf5aabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[\n",
    "        register_model_step, deploy_step\n",
    "    ],\n",
    "    else_steps=[fail_step], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2efcaa8-0d82-4795-9016-1a6479a476de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session5_pipeline = Pipeline(\n",
    "    name=\"mnist-session5-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination,\n",
    "        timestamp_signature,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "        data_capture_enabled,\n",
    "        data_capture_percentage,\n",
    "        data_capture_destination,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        tuning_step if USE_TUNING_STEP else training_step, \n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38b5b194-12e3-40d8-980a-f4b7b0845c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session5_pipeline.upsert(role_arn=role)\n",
    "\n",
    "# execution = session5_pipeline.start(parameters=dict(\n",
    "#     timestamp_signature=time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffbd37d-37f5-4600-8e5b-462a3c0560a2",
   "metadata": {},
   "source": [
    "# Data Monitoring"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f78ca30a-ca9f-469b-9d3f-845142e02c5b",
   "metadata": {},
   "source": [
    "This session aims to set up a monitoring process to analyze the quality of the data and the model. For this, we will have SageMaker capture and evaluate the data observed by the endpoint.\n",
    "\n",
    "To enable this functionality, we need a couple of steps:\n",
    "\n",
    "Create a baseline to compare the real-time traffic.\n",
    "Set up a schedule to continuously evaluate and compare against the baseline.\n",
    "Notice that the Data and Model Quality processes use the baseline dataset we generated during preprocessing. This baseline dataset is the same unprocessed train set in JSON format. We do this because we transformed the train data during the preprocessing step, but we need raw data because that's what the endpoint expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c5f4057-e828-4abf-acc0-1f8fbb1002db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from threading import Thread, Event\n",
    "\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.quality_check_step import DataQualityCheckConfig, QualityCheckStep, ModelQualityCheckConfig\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.workflow.parameters import ParameterBoolean\n",
    "from sagemaker.inputs import CreateModelInput, TransformInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.workflow.steps import CreateModelStep, TransformStep\n",
    "from sagemaker.model_monitor import CronExpressionGenerator, EndpointInput, DefaultModelMonitor, ModelQualityMonitor, DatasetFormat\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.s3 import S3Uploader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61792983-80f2-4bc9-912c-267bc37b7698",
   "metadata": {},
   "source": [
    "## Data Quality Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45315251-d3a3-4cb5-9ef4-b95144fd2411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_quality_skip_check = ParameterBoolean(\n",
    "    name=\"data_quality_skip_check\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "data_quality_register_new_baseline = ParameterBoolean(\n",
    "    name=\"data_quality_register_new_baseline\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "data_quality_supplied_baseline_statistics = ParameterString(\n",
    "    name=\"data_quality_supplied_baseline_statistics\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "data_quality_supplied_baseline_constraints = ParameterString(\n",
    "    name=\"data_quality_supplied_baseline_constraints\", \n",
    "    default_value=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba054d7-77b7-472a-8087-16f3a62696bc",
   "metadata": {},
   "source": [
    "## Set up data quality check step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7207c1f6-9fd3-4614-83da-ecebd8477ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_job_config = CheckJobConfig(\n",
    "    instance_type=\"ml.t3.xlarge\",\n",
    "    instance_count=1,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size_in_gb=20,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "data_quality_check_config = DataQualityCheckConfig(\n",
    "    # We will use the train dataset we generated during the preprocessing \n",
    "    # step to generate the data quality baseline.\n",
    "    baseline_dataset=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"train-baseline\"].S3Output.S3Uri,\n",
    "    \n",
    "    dataset_format=DatasetFormat.json(lines=True),\n",
    "    output_s3_uri=Join(on='/', values=[S3_FILEPATH, \"monitoring\", \"data-quality\"]),\n",
    ")\n",
    "\n",
    "data_quality_check_step = QualityCheckStep(\n",
    "    name=\"data-quality-check\",\n",
    "    check_job_config=check_job_config,\n",
    "    quality_check_config=data_quality_check_config,\n",
    "    skip_check=data_quality_skip_check,\n",
    "    register_new_baseline=data_quality_register_new_baseline,\n",
    "    supplied_baseline_statistics=data_quality_supplied_baseline_statistics,\n",
    "    supplied_baseline_constraints=data_quality_supplied_baseline_constraints,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb73b19-84e7-49fa-8505-8c883af3f60c",
   "metadata": {},
   "source": [
    "# Model Quality Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e84ac6c-4ac6-442c-916a-02ab78bfc57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_skip_check = ParameterBoolean(\n",
    "    name=\"model_quality_skip_check\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "model_quality_register_new_baseline = ParameterBoolean(\n",
    "    name=\"model_quality_register_new_baseline\", \n",
    "    default_value=True\n",
    ")\n",
    "\n",
    "model_quality_supplied_baseline_statistics = ParameterString(\n",
    "    name=\"model_quality_supplied_baseline_statistics\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "model_quality_supplied_baseline_constraints = ParameterString(\n",
    "    name=\"model_quality_supplied_baseline_constraints\", \n",
    "    default_value=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aef7bb-6f90-40a9-8a85-3bf01757259e",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd311ef0-992a-4864-8251-b6d5edc020a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.13.1\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    env={\n",
    "        \"PIPELINE_S3_LOCATION\": preprocessor_destination,\n",
    "    },\n",
    "    py_version=\"py39\",\n",
    "    role=role,\n",
    "    entry_point = \"inference.py\",\n",
    "    source_dir=str(CODE_FOLDER),\n",
    ")\n",
    "\n",
    "create_model_step = ModelStep(\n",
    "    name=\"create-model\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531fa45-7440-4484-919a-1eeeb664cebe",
   "metadata": {},
   "source": [
    "## Generate baseline predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2a427802-42a2-429d-9241-c957ba81ebfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    # We can specify the name of the model the Batch Transform Job will \n",
    "    # use by using the property from the Model Step that created the model.\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    instance_count=1,\n",
    "    \n",
    "    # The baseline set that we generated in the preprocessing step\n",
    "    # is in JSON format, where every line is a JSON sample.\n",
    "    accept=\"application/json\",\n",
    "    strategy=\"SingleRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    \n",
    "    output_path=f\"{S3_FILEPATH}/transform\",\n",
    ")\n",
    "\n",
    "transform_step = TransformStep(\n",
    "    name=\"transform\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(\n",
    "        \n",
    "        # We will use the test dataset we generated during the preprocessing \n",
    "        # step to run it through the model and generate predictions.\n",
    "        data=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"test-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        join_source=\"Input\",\n",
    "        content_type=\"application/json\",\n",
    "        split_type=\"Line\",\n",
    "    ),\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2a073-a4eb-4713-a2fd-6e5cd9b6d83d",
   "metadata": {},
   "source": [
    "## Set up model quality check step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "075bdb0b-b3e6-4f95-9b51-5eaa95807198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_check_config = ModelQualityCheckConfig(\n",
    "    # We are going to use the output of the Transform Step to generate\n",
    "    # the model quality baseline.\n",
    "    baseline_dataset=transform_step.properties.TransformOutput.S3OutputPath,\n",
    "    \n",
    "    dataset_format=DatasetFormat.json(lines=True),\n",
    "    output_s3_uri=Join(on='/', values=[S3_FILEPATH, \"monitoring\", \"model-quality\"]),\n",
    "    \n",
    "    # We need to specify the problem type and the fields where the prediction\n",
    "    # and groundtruth are so the process knows how to interpret the results.\n",
    "    problem_type=\"MulticlassClassification\",\n",
    "    inference_attribute=\"$.SageMakerOutput.prediction\",\n",
    "    ground_truth_attribute=\"groundtruth\",\n",
    ")\n",
    "\n",
    "model_quality_check_step = QualityCheckStep(\n",
    "    name=\"model-quality-check\",\n",
    "    check_job_config=check_job_config,\n",
    "    quality_check_config=model_quality_check_config,\n",
    "    skip_check=model_quality_skip_check,\n",
    "    register_new_baseline=model_quality_register_new_baseline,\n",
    "    supplied_baseline_statistics=model_quality_supplied_baseline_statistics,\n",
    "    supplied_baseline_constraints=model_quality_supplied_baseline_constraints,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b1ff6-88ad-42c5-a132-74f09822c698",
   "metadata": {},
   "source": [
    "## Set up model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "357485ca-c0ef-4eb7-a018-955a3bdfc49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    \n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58541c4d-6fe8-4944-822c-a3fcd04d4880",
   "metadata": {},
   "source": [
    "## Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3dcefee3-b5cf-44cd-a338-af6e59056017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=model_approval_status,\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.13.1\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d9fed-dc7b-4f7e-8e5d-83d9f522e7ca",
   "metadata": {},
   "source": [
    "## Set up condition step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "349ddc1f-0466-4adb-a513-34355e676adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[\n",
    "        create_model_step, \n",
    "        transform_step, \n",
    "        model_quality_check_step, \n",
    "        register_model_step,\n",
    "        deploy_step\n",
    "    ],\n",
    "    else_steps=[fail_step], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cbae6-6de5-40ce-8d22-f46b628673ea",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91a6a1b5-2a8f-47ae-a134-080f02bc4470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session6_pipeline = Pipeline(\n",
    "    name=\"mnist-session6-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        train_dataset_baseline_destination,\n",
    "        test_dataset_baseline_destination,\n",
    "        timestamp_signature,\n",
    "        data_capture_enabled,\n",
    "        data_capture_percentage,\n",
    "        data_capture_destination,\n",
    "        data_quality_skip_check,\n",
    "        data_quality_register_new_baseline,\n",
    "        data_quality_supplied_baseline_statistics,\n",
    "        data_quality_supplied_baseline_constraints,\n",
    "        model_quality_skip_check,\n",
    "        model_quality_register_new_baseline,\n",
    "        model_quality_supplied_baseline_statistics,\n",
    "        model_quality_supplied_baseline_constraints,\n",
    "        evaluation_destination,\n",
    "        model_approval_status,\n",
    "        accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_step, \n",
    "        data_quality_check_step,\n",
    "        tuning_step if USE_TUNING_STEP else training_step, \n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "986aa107-5cbc-4ad4-a7d7-1ebd300942a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    }
   ],
   "source": [
    "session6_pipeline.upsert(role_arn=role)\n",
    "execution = session6_pipeline.start(parameters=dict(\n",
    "    timestamp_signature=time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
